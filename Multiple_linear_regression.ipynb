{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Multiple_linear_regression.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tyler04/Machine-Learning-A-Z-in-Python-Notes/blob/main/Multiple_linear_regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CazISR8X_HUG"
      },
      "source": [
        "# Multiple Linear Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Notes on Regression"
      ],
      "metadata": {
        "id": "tgLbT2LqHDQp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Whenever we have categorical data we have to encode that by using **dummy variables**.\n",
        "\n",
        "A dummy variable is a numerical variable used in regression analysis to represent subgroups of the sample in your study. In research design, a dummy variable is often used to distinguish different treatment groups. In the simplest case, we would use a 0,1 dummy variable where a person is given a value of 0 if they are in the control group or a 1 if they are in the treated group. Dummy variables are useful because they enable us to use a single regression equation to represent multiple groups. This means that we donâ€™t need to write out separate equation models for each subgroup.\n",
        "\n"
      ],
      "metadata": {
        "id": "DVUX_0Bn6em5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Dummy variable Trap**\n",
        "\n",
        "The Dummy Variable Trap occurs when two or more dummy variables created by one-hot encoding are highly correlated (multi-collinear). This means that one variable can be predicted from the others, making it difficult to interpret predicted coefficient variables in regression models. In other words, the individual effect of the dummy variables on the prediction model can not be interpreted well because of multicollinearity.\n",
        "\n",
        "Using the one-hot encoding method, a new dummy variable is created for each categorical variable to represent the presence (1) or absence (0) of the categorical variable. For example, if tree species is a categorical variable made up of the values pine or oak, then tree species can be represented as a dummy variable by converting each variable to a one-hot vector. This means that a separate column is obtained for each category, where the first column represents if the tree is pine and the second column represents if the tree is oak. Each column will contain a 0 or 1 if the tree in question is of the column's species. These two columns are multi-collinear since if a tree is pine, then we know it's not oak and vice versa.\n",
        "\n",
        "To overcome the Dummy variable Trap, we drop one of the columns created when the categorical variables were converted to dummy variables by one-hot encoding. This can be done because the dummy variables include redundant information.\n",
        "\n"
      ],
      "metadata": {
        "id": "0eWqOIwM7h22"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Building a Model**\n",
        "\n",
        "The dependent variable is affected by multiple factors now, but we have to get rid of some indepent variables. \n",
        "\n",
        "So why not use every independent variables?\n",
        "\n",
        "1. Most of the independent variables may not effect the actual prediction.\n",
        "2. If there are 1000 variables it is not feasible to explain each of them individually.\n",
        "\n",
        "\n",
        "**5 methods to build a model**\n",
        "\n",
        "1. All-in\n",
        "\n",
        "Step wise Regression\n",
        "\n",
        "    2. Backward Elimination\n",
        "    3. Forward selection\n",
        "    4. Bidirectional Elimination\n",
        "5. Score comparison"
      ],
      "metadata": {
        "id": "_qqeDq_i_fVw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. All-in\n",
        "  * Throwing all the independent variables to the model.\n",
        "  * We can use this when we have prior knowledge about the data and we know every variable is important (true predictor).\n",
        "  * You have to use (not your choice)\n",
        "  * Preparing for backward elimination\n",
        "\n",
        "2. Backward Elimination\n",
        "  1. Select a significance level to **stay** in the model. (eg. SL=0.05)\n",
        "  2. Fit the full model with all possible predictors. (All-in approach)\n",
        "  3. Consider the predictors with highest p-values. If p > SL go to step 4, otherwise FIN.\n",
        "  4. Remove the predictors.\n",
        "  5. Fit the model without these variables.\n",
        "  Return to step 3. \n",
        "\n",
        "\n",
        "3. Forward Selection\n",
        "  1. Select a significance level to **enter** the model. (eg. SL=0.05)\n",
        "  2. Fit all possible simple regression models y~x. Select one with lowest p-value.\n",
        "  3. Keep this variable and create all possible models with one extra predictor added to one(s) you already have.\n",
        "  4. Consider the predictor with lowest p. If p < SL go to step 3 otherwise FIN.\n",
        "\n",
        "\n",
        "4. Bidirectional Elimination\n",
        "  1. Select a significance level to **stay** and to **enter** the model. (eg. SL=0.05)\n",
        "  2. Perform the next steps of forward selection. (new variable must have p < SLENTER)\n",
        "  3. Perfom ALL the steps of backward elimination. Go to step 2.\n",
        "  4. No new or old variables can remove form the model. FIN\n",
        "\n",
        "\n",
        "5. All possible model/ Score comparison\n",
        "  1.  Select a criterion for good fit. \n",
        "  2. Construct all possible regression models\n",
        "  3. Select one with best criterion. then FIN\n",
        "  \n",
        "  But it is insane to apply, as 10 columns have 1023 models. \n",
        "\n"
      ],
      "metadata": {
        "id": "H06uXi9bBJTx"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pOyqYHTk_Q57"
      },
      "source": [
        "## Importing the libraries"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "metadata": {
        "id": "x3AVUlfS1Mhk"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vgC61-ah_WIz"
      },
      "source": [
        "## Importing the dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset= pd.read_csv('50_Startups.csv')\n",
        "X= dataset.iloc[:, :-1].values\n",
        "y= dataset.iloc[:, -1]. values"
      ],
      "metadata": {
        "id": "-y07uXKX3Qn2"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GOB3QhV9B5kD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8286ffca-75f5-47e9-eb94-653413a6b51d"
      },
      "source": [
        "print(X)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[165349.2 136897.8 471784.1 'New York']\n",
            " [162597.7 151377.59 443898.53 'California']\n",
            " [153441.51 101145.55 407934.54 'Florida']\n",
            " [144372.41 118671.85 383199.62 'New York']\n",
            " [142107.34 91391.77 366168.42 'Florida']\n",
            " [131876.9 99814.71 362861.36 'New York']\n",
            " [134615.46 147198.87 127716.82 'California']\n",
            " [130298.13 145530.06 323876.68 'Florida']\n",
            " [120542.52 148718.95 311613.29 'New York']\n",
            " [123334.88 108679.17 304981.62 'California']\n",
            " [101913.08 110594.11 229160.95 'Florida']\n",
            " [100671.96 91790.61 249744.55 'California']\n",
            " [93863.75 127320.38 249839.44 'Florida']\n",
            " [91992.39 135495.07 252664.93 'California']\n",
            " [119943.24 156547.42 256512.92 'Florida']\n",
            " [114523.61 122616.84 261776.23 'New York']\n",
            " [78013.11 121597.55 264346.06 'California']\n",
            " [94657.16 145077.58 282574.31 'New York']\n",
            " [91749.16 114175.79 294919.57 'Florida']\n",
            " [86419.7 153514.11 0.0 'New York']\n",
            " [76253.86 113867.3 298664.47 'California']\n",
            " [78389.47 153773.43 299737.29 'New York']\n",
            " [73994.56 122782.75 303319.26 'Florida']\n",
            " [67532.53 105751.03 304768.73 'Florida']\n",
            " [77044.01 99281.34 140574.81 'New York']\n",
            " [64664.71 139553.16 137962.62 'California']\n",
            " [75328.87 144135.98 134050.07 'Florida']\n",
            " [72107.6 127864.55 353183.81 'New York']\n",
            " [66051.52 182645.56 118148.2 'Florida']\n",
            " [65605.48 153032.06 107138.38 'New York']\n",
            " [61994.48 115641.28 91131.24 'Florida']\n",
            " [61136.38 152701.92 88218.23 'New York']\n",
            " [63408.86 129219.61 46085.25 'California']\n",
            " [55493.95 103057.49 214634.81 'Florida']\n",
            " [46426.07 157693.92 210797.67 'California']\n",
            " [46014.02 85047.44 205517.64 'New York']\n",
            " [28663.76 127056.21 201126.82 'Florida']\n",
            " [44069.95 51283.14 197029.42 'California']\n",
            " [20229.59 65947.93 185265.1 'New York']\n",
            " [38558.51 82982.09 174999.3 'California']\n",
            " [28754.33 118546.05 172795.67 'California']\n",
            " [27892.92 84710.77 164470.71 'Florida']\n",
            " [23640.93 96189.63 148001.11 'California']\n",
            " [15505.73 127382.3 35534.17 'New York']\n",
            " [22177.74 154806.14 28334.72 'California']\n",
            " [1000.23 124153.04 1903.93 'New York']\n",
            " [1315.46 115816.21 297114.46 'Florida']\n",
            " [0.0 135426.92 0.0 'California']\n",
            " [542.05 51743.15 0.0 'New York']\n",
            " [0.0 116983.8 45173.06 'California']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hnyL15rBHyig",
        "outputId": "7f519234-e661-40ab-e24b-82bc1a1f7e12"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 50 entries, 0 to 49\n",
            "Data columns (total 5 columns):\n",
            " #   Column           Non-Null Count  Dtype  \n",
            "---  ------           --------------  -----  \n",
            " 0   R&D Spend        50 non-null     float64\n",
            " 1   Administration   50 non-null     float64\n",
            " 2   Marketing Spend  50 non-null     float64\n",
            " 3   State            50 non-null     object \n",
            " 4   Profit           50 non-null     float64\n",
            "dtypes: float64(4), object(1)\n",
            "memory usage: 2.1+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VadrvE7s_lS9"
      },
      "source": [
        "## Encoding categorical data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "ct= ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [3])], remainder='passthrough')\n",
        "X = np.array(ct.fit_transform(X))"
      ],
      "metadata": {
        "id": "bzgAlssfH7eJ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ym3HdYeCGYG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2bb0d735-d469-4abf-c14a-87d6da1c2279"
      },
      "source": [
        "print(X)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.0 0.0 1.0 165349.2 136897.8 471784.1]\n",
            " [1.0 0.0 0.0 162597.7 151377.59 443898.53]\n",
            " [0.0 1.0 0.0 153441.51 101145.55 407934.54]\n",
            " [0.0 0.0 1.0 144372.41 118671.85 383199.62]\n",
            " [0.0 1.0 0.0 142107.34 91391.77 366168.42]\n",
            " [0.0 0.0 1.0 131876.9 99814.71 362861.36]\n",
            " [1.0 0.0 0.0 134615.46 147198.87 127716.82]\n",
            " [0.0 1.0 0.0 130298.13 145530.06 323876.68]\n",
            " [0.0 0.0 1.0 120542.52 148718.95 311613.29]\n",
            " [1.0 0.0 0.0 123334.88 108679.17 304981.62]\n",
            " [0.0 1.0 0.0 101913.08 110594.11 229160.95]\n",
            " [1.0 0.0 0.0 100671.96 91790.61 249744.55]\n",
            " [0.0 1.0 0.0 93863.75 127320.38 249839.44]\n",
            " [1.0 0.0 0.0 91992.39 135495.07 252664.93]\n",
            " [0.0 1.0 0.0 119943.24 156547.42 256512.92]\n",
            " [0.0 0.0 1.0 114523.61 122616.84 261776.23]\n",
            " [1.0 0.0 0.0 78013.11 121597.55 264346.06]\n",
            " [0.0 0.0 1.0 94657.16 145077.58 282574.31]\n",
            " [0.0 1.0 0.0 91749.16 114175.79 294919.57]\n",
            " [0.0 0.0 1.0 86419.7 153514.11 0.0]\n",
            " [1.0 0.0 0.0 76253.86 113867.3 298664.47]\n",
            " [0.0 0.0 1.0 78389.47 153773.43 299737.29]\n",
            " [0.0 1.0 0.0 73994.56 122782.75 303319.26]\n",
            " [0.0 1.0 0.0 67532.53 105751.03 304768.73]\n",
            " [0.0 0.0 1.0 77044.01 99281.34 140574.81]\n",
            " [1.0 0.0 0.0 64664.71 139553.16 137962.62]\n",
            " [0.0 1.0 0.0 75328.87 144135.98 134050.07]\n",
            " [0.0 0.0 1.0 72107.6 127864.55 353183.81]\n",
            " [0.0 1.0 0.0 66051.52 182645.56 118148.2]\n",
            " [0.0 0.0 1.0 65605.48 153032.06 107138.38]\n",
            " [0.0 1.0 0.0 61994.48 115641.28 91131.24]\n",
            " [0.0 0.0 1.0 61136.38 152701.92 88218.23]\n",
            " [1.0 0.0 0.0 63408.86 129219.61 46085.25]\n",
            " [0.0 1.0 0.0 55493.95 103057.49 214634.81]\n",
            " [1.0 0.0 0.0 46426.07 157693.92 210797.67]\n",
            " [0.0 0.0 1.0 46014.02 85047.44 205517.64]\n",
            " [0.0 1.0 0.0 28663.76 127056.21 201126.82]\n",
            " [1.0 0.0 0.0 44069.95 51283.14 197029.42]\n",
            " [0.0 0.0 1.0 20229.59 65947.93 185265.1]\n",
            " [1.0 0.0 0.0 38558.51 82982.09 174999.3]\n",
            " [1.0 0.0 0.0 28754.33 118546.05 172795.67]\n",
            " [0.0 1.0 0.0 27892.92 84710.77 164470.71]\n",
            " [1.0 0.0 0.0 23640.93 96189.63 148001.11]\n",
            " [0.0 0.0 1.0 15505.73 127382.3 35534.17]\n",
            " [1.0 0.0 0.0 22177.74 154806.14 28334.72]\n",
            " [0.0 0.0 1.0 1000.23 124153.04 1903.93]\n",
            " [0.0 1.0 0.0 1315.46 115816.21 297114.46]\n",
            " [1.0 0.0 0.0 0.0 135426.92 0.0]\n",
            " [0.0 0.0 1.0 542.05 51743.15 0.0]\n",
            " [1.0 0.0 0.0 0.0 116983.8 45173.06]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "72IlRMiPIb7n",
        "outputId": "e05277c2-817d-4543-f850-9feaae73f495"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 50 entries, 0 to 49\n",
            "Data columns (total 5 columns):\n",
            " #   Column           Non-Null Count  Dtype  \n",
            "---  ------           --------------  -----  \n",
            " 0   R&D Spend        50 non-null     float64\n",
            " 1   Administration   50 non-null     float64\n",
            " 2   Marketing Spend  50 non-null     float64\n",
            " 3   State            50 non-null     object \n",
            " 4   Profit           50 non-null     float64\n",
            "dtypes: float64(4), object(1)\n",
            "memory usage: 2.1+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WemVnqgeA70k"
      },
      "source": [
        "## Splitting the dataset into the Training set and Test set"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
      ],
      "metadata": {
        "id": "eSUXBphQIo7o"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-McZVsQBINc"
      },
      "source": [
        "## Training the Multiple Linear Regression model on the Training set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ywPjx0L1BMiD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8784fde6-7a99-472a-c4d7-b4052f5b57cf"
      },
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "regressor = LinearRegression()\n",
        "regressor.fit(X_train, y_train)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LinearRegression()"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xNkXL1YQBiBT"
      },
      "source": [
        "## Predicting the Test set results"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = regressor.predict(X_test)\n",
        "np.set_printoptions(precision=2)\n",
        "print(np.concatenate((y_pred.reshape(len(y_pred), 1), y_test.reshape(len(y_pred), 1)), 1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vwI7i1PnLAXc",
        "outputId": "d5d5a227-f918-4915-c536-1056694ed5bd"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[103015.2  103282.38]\n",
            " [132582.28 144259.4 ]\n",
            " [132447.74 146121.95]\n",
            " [ 71976.1   77798.83]\n",
            " [178537.48 191050.39]\n",
            " [116161.24 105008.31]\n",
            " [ 67851.69  81229.06]\n",
            " [ 98791.73  97483.56]\n",
            " [113969.44 110352.25]\n",
            " [167921.07 166187.94]]\n"
          ]
        }
      ]
    }
  ]
}